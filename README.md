# MXINT_quantization
1. MXINT Quantization on transformer-based models
2. Attention pruning methods
   a. top-k
   b. threshold-based
3. Exponent-based attention prediction
